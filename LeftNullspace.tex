
\section{\label{sec:computeRightFactor}Computing the Right Factor}

Let $\mathbf{N}$ be an $\left(\mathbf{F},\vec{s}\right)$-kernel
basis computed using the existing algorithm from \cite{za2012}. Consider
now the problem of computing a left $-\vec{s}$-minimal kernel basis
$\mathbf{G}$ for $\mathbf{N}$, or equivalently, a $\left(\mathbf{N}^{T},-\vec{s}\right)$-kernel
basis $\mathbf{G}^{T}$. For this problem, the fast kernel algorithm
of \cite{za2012} cannot be applied directly, since the input matrix
$\mathbf{N}^{T}$ has nonuniform row degrees and negative shift. Comparing
to the earlier problem of computing a $\vec{s}$-minimal kernel basis
$\mathbf{N}$ for $\mathbf{F}$, it is interesting to note that the
original output $\mathbf{N}$ now becomes the new input matrix $\mathbf{N}^{T}$,
while the new output matrix $\mathbf{G}$ has size bounded by $\mathbf{F}$.
In other words, the new input has degrees that match the original
output, while the new output has degrees bounded by the original input.
It is therefore reasonable to expect that the new problem can be computed
efficiently. However, we need to find some way to work with the more
complicated input degree structure. On the other hand, the simpler
output degree structure makes it easier to apply order basis computation
in order to compute a $\left(\mathbf{N}^{T},-\vec{s}\right)$-kernel
basis.


\subsection{Kernel Bases via Order Bases}

In order to see how order basis computations can be applied here,
let us first recall the following result (Lemma 3.3 \cite{za2012})
on a relationship between order bases and kernel bases.
\begin{lem}
\label{lem:orderBasisContainsNullspaceBasis}Let $\mathbf{P}=\left[\mathbf{P}_{L},\mathbf{P}_{R}\right]$
be any $\left(\mathbf{F},\sigma,\vec{s}\right)$-basis and $\mathbf{N}=\left[\mathbf{N}_{L},\mathbf{N}_{R}\right]$
be any $\vec{s}$-minimal kernel basis of $\mathbf{F}$, where $\mathbf{P}_{L}$
and $\mathbf{N}_{L}$ contain all columns from $\mathbf{P}$ and $\mathbf{N}$,
respectively, whose $\vec{s}$-column degrees are less than $\sigma$.
Then $\left[\mathbf{P}_{L},\mathbf{N}_{R}\right]$ is a $\vec{s}$-minimal
kernel basis of $\mathbf{F}$, and $\left[\mathbf{N}_{L},\mathbf{P}_{R}\right]$
is a $\left(\mathbf{F},\sigma,\vec{s}\right)$-basis.
\end{lem}
It is not difficult to extend this result to the following lemma to
accommodate our situation here.%
\begin{comment}
 For the remainder of this paper an integer vector of ones is denoted
by $\vec{e}$. 
\end{comment}

\begin{lem}
\label{lem:orderbasisContainsKernelbasisGeneralized} Given a matrix
$\mathbf{A}\in\mathbb{K}\left[x\right]^{m\times n}$ and some integer
lists $\vec{u}\in\mathbb{Z}^{n}$ and $\vec{v}\in\mathbb{Z}^{m}$
such that $\rdeg_{\vec{u}}\mathbf{A}\le\vec{v}$, or equivalently,
$\cdeg_{-\vec{v}}\mathbf{A}\le-\vec{u}$. Let $\mathbf{P}$ be a $\left(\mathbf{A},\vec{v}+1,-\vec{u}\right)$
order basis and $\mathbf{Q}$ be any $(\mathbf{A},-\vec{u})$-kernel
basis. Partition $\mathbf{P}=\left[\mathbf{P}_{L},\mathbf{P}_{R}\right]$
and $\mathbf{Q}=\left[\mathbf{Q}_{L},\mathbf{Q}_{R}\right]$ where
$\mathbf{P}_{L}$ and $\mathbf{Q}_{L}$ contain all the columns from
$\mathbf{P}$ and $\mathbf{Q}$, respectively, whose $-\vec{u}$-column
degrees are no more than $0$. Then 
\begin{itemize}
\item $\left[\mathbf{P}_{L},\mathbf{Q}_{R}\right]$ is an $(\mathbf{A},-\vec{u})$-kernel
basis, and 
\item $\left[\mathbf{Q}_{L},\mathbf{P}_{R}\right]$ is an $\left(\mathbf{A},\vec{v}+1,-\vec{u}\right)$
order basis. 
\end{itemize}
\end{lem}
\begin{proof}
We can use the same proof from Lemma 3.3 in \cite{za2012}. We know
$\cdeg_{-\vec{v}}\mathbf{A}\mathbf{P}_{L}\le\cdeg_{-\vec{u}}\mathbf{P}_{L}\le0$,
or equivalently, $\rdeg\mathbf{A}\mathbf{P}_{L}\le\vec{v}$. However
it also has order greater than $\vec{v}$ and hence $\mathbf{A}\mathbf{P}_{L}=0$.
Thus $\mathbf{P}_{L}$ is generated by the kernel basis$\mathbf{Q}_{L}$,
that is, $\mathbf{P}_{L}=\mathbf{Q}_{L}\mathbf{U}$ for some polynomial
matrix $\mathbf{U}$. On the other hand, $\mathbf{Q}_{L}$ certainly
has order $\left(\mathbf{A},\vec{v}+1\right)$ and therefore is generated
by $\mathbf{P}_{L}$, that is, $\mathbf{Q}_{L}=\mathbf{P}_{L}\mathbf{V}$
for some polynomial matrix $\mathbf{V}$. We now have $\mathbf{P}_{L}=\mathbf{P}_{L}\mathbf{V}\mathbf{U}$
and $\mathbf{Q}_{L}=\mathbf{Q}_{L}\mathbf{U}\mathbf{V}$, implying
both $\mathbf{U}$ and $\mathbf{V}$ are unimodular. The result then
follows from the unimodular equivalence of $\mathbf{P}_{L}$ and $\mathbf{Q}_{L}$
and the fact that they are $-\vec{u}$-column reduced.
\end{proof}
With the help of Lemma \ref{lem:orderbasisContainsKernelbasisGeneralized}
we can return to the problem of efficiently computing a $(\mathbf{F},\vec{s})$
kernel basis. In fact, we just need to use a special case of Lemma
\ref{lem:orderbasisContainsKernelbasisGeneralized}, where all the
elements of the kernel basis have shifted degrees bounded by $0$,
thereby making the partial kernel basis be a complete kernel basis. 
\begin{lem}
\label{lem:kernelBasisInOrderBasis} Let $\mathbf{N}$ be a $(\mathbf{F},\vec{s})$
kernel basis with $\cdeg_{\vec{s}}~\mathbf{N}=\vec{b}$. Let $\mathbf{P}=\left[\mathbf{P}_{L},\mathbf{P}_{R}\right]$
be a $\left(\mathbf{N}^{T},\vec{b}+1,-\vec{s}\right)$ order basis,
where $\mathbf{P}_{L}$ consists of all columns $\mathbf{p}$ satisfying
$\cdeg_{-\vec{s}}~\mathbf{p}\le0$. Then $\mathbf{P}_{L}$ is a $(\mathbf{N}^{T},-\vec{s})$-kernel
basis. \end{lem}
\begin{proof}
Let the rank of $\mathbf{F}$ be $r$, which is also the column dimension
of any $(\mathbf{N}^{T},-\vec{s})$-kernel basis $\mathbf{G}^{T}$.
Since both $\mathbf{F}$ and $\mathbf{G}$ are in the left kernel
of $\mathbf{N}$, we know $\mathbf{F}$ is generated by $\mathbf{G}$,
and the $-\vec{s}$-minimality of $\mathbf{G}$ ensures that the $-\vec{s}$-row
degrees of $\mathbf{G}$ are bounded by the corresponding $r$ largest
$-\vec{s}$-row degrees of $\mathbf{F}$, which are in turn bounded
by $0$ since $\cdeg\mathbf{F}\le\vec{s}$. Therefore, any $(\mathbf{N}^{T},-\vec{s})$-kernel
basis $\mathbf{G}^{T}$ satisfies $\cdeg_{-\vec{s}}\mathbf{G}^{T}\le0$.
The result now follows from Lemma \ref{lem:orderbasisContainsKernelbasisGeneralized}. 
\end{proof}
We can use Theorem \ref{thm:continueComputingKernelBasisByRows} to
compute a $\left(\mathbf{N}^{T},-\vec{s}\right)$-kernel basis by
rows. We partition $\mathbf{N}$ into $\left[\mathbf{N}_{1},\mathbf{N}_{2}\right]$
with $\vec{s}$-column degrees $\vec{b}_{1}$, $\vec{b}_{2}$ respectively.
We first compute a $\left(\mathbf{N}_{1}^{T},-\vec{s}\right)$-kernel
basis $\mathbf{Q}_{1}$ with $-\vec{s}$-column degrees $-\vec{s}_{2}$,
and then compute a $\left(\mathbf{N}_{2}^{T}\mathbf{Q}_{1},-\vec{s}_{2}\right)$-kernel
basis $\mathbf{Q}_{2}$ implying that $\mathbf{Q}_{1}\mathbf{Q}_{2}$
is a $\left(\mathbf{N}^{T},-\vec{s}\right)$-kernel basis. In order
to compute the kernel bases $\mathbf{Q}_{1}$ and $\mathbf{Q}_{2}$,
we can use order basis computation. However, we need to make sure
that the order bases we compute contain these kernel bases.
\begin{lem}
\label{lem:kernelBasisOfSubsetOfRowsContainedInOrderBasis} Let $\mathbf{N}$
be partitioned as $\left[\mathbf{N}_{1},\mathbf{N}_{2}\right]$, with
$\vec{s}$-column degrees $\vec{b}_{1}$, $\vec{b}_{2}$, respectively.
Then we have the following:
\begin{enumerate}
\item A $\left(\mathbf{N}_{1}^{T},\vec{b}_{1}+1,-\vec{s}\right)$ order
basis contains a $\left(\mathbf{N}_{1}^{T},-\vec{s}\right)$-kernel
basis whose $-\vec{s}$-column degrees are bounded by $0$. 
\item If $\mathbf{Q}_{1}$ is this $\left(\mathbf{N}_{1}^{T},-\vec{s}\right)$-kernel
basis from above and $-\vec{s}_{2}=\cdeg_{-\vec{s}}\mathbf{Q}_{1}$,
then a $\left(\mathbf{N}_{2}^{T}\mathbf{Q}_{1},\vec{b}_{2}+1,-\vec{s}_{2}\right)$-basis
contains a $\left(\mathbf{N}_{2}^{T}\mathbf{Q}_{1},-\vec{s}_{2}\right)$-kernel
basis, $\mathbf{Q}_{2}$, whose $-\vec{s}$-column degrees are bounded
by $0$. 
\item The product $\mathbf{Q}_{1}\mathbf{Q}_{2}$ is a $\left(\mathbf{N}^{T},-\vec{s}\right)$
kernel basis. 
\end{enumerate}
\end{lem}
\begin{proof}
To see that a $\left(\mathbf{N}_{1}^{T},\vec{b}_{1}+1,-\vec{s}\right)$-basis
contains a $\left(\mathbf{N}_{1}^{T},-\vec{s}\right)$-kernel basis
whose $-\vec{s}$-column degrees are bounded by 0, we just need to
show that $\cdeg_{-\vec{s}}\mathbf{\bar{Q}}_{1}\le0$ for any $\left(\mathbf{N}_{1}^{T},-\vec{s}\right)$-kernel
basis $\mathbf{\bar{Q}}_{1}$ and then apply \prettyref{lem:orderbasisContainsKernelbasisGeneralized}.
Note that there exists a polynomial matrix $\bar{\mathbf{Q}}_{2}$
such that $\mathbf{\bar{Q}}_{1}\mathbf{\bar{Q}}_{2}=\bar{\mathbf{G}}$
for any $\left(\mathbf{N}^{T},-\vec{s}\right)$-kernel basis $\bar{\mathbf{G}}$,
as $\bar{\mathbf{G}}$ satisfies $\mathbf{N}_{1}^{T}\bar{\mathbf{G}}=0$
and is therefore generated by the $\left(\mathbf{N}_{1}^{T},-\vec{s}\right)$-kernel
basis $\bar{\mathbf{Q}}_{1}$. If $\cdeg_{-\vec{s}}\mathbf{\bar{Q}}_{1}\nleq0$,
then \prettyref{lem:predictableDegree} forces 
\[
\cdeg_{-\vec{s}}\left(\bar{\mathbf{Q}}_{1}\bar{\mathbf{Q}}_{2}\right)=\cdeg_{-\vec{s}}\bar{\mathbf{G}}\nleq0,
\]
 a contradiction since we know from the proof of \prettyref{lem:kernelBasisInOrderBasis}
that $\cdeg_{-\vec{s}}\mathbf{G}^{T}\le0$. 

As before, to see that a $\left(\mathbf{N}_{2}^{T}\mathbf{Q}_{1},\vec{b}_{2}+1,-\vec{s}_{2}\right)$-basis
contains a $\left(\mathbf{N}_{2}^{T}\mathbf{Q}_{1},-\vec{s}_{2}\right)$-kernel
basis whose $-\vec{s}$-column degrees are no more than 0, we can
just show $\cdeg_{-\vec{s}_{2}}\hat{\mathbf{Q}}_{2}\le0$ for any
$\left(\mathbf{N}_{2}^{T}\mathbf{Q}_{1},-\vec{s}_{2}\right)$-kernel
basis $\hat{\mathbf{Q}}_{2}$ and then apply \prettyref{lem:orderbasisContainsKernelbasisGeneralized}.
Since $\cdeg_{\vec{s}}\mathbf{N}_{2}=\vec{b}_{2}$, we have $\rdeg_{-\vec{b}_{2}}\mathbf{N}_{2}\le-\vec{s}$
or equivalently, $\cdeg_{-\vec{b}_{2}}\mathbf{N}_{2}^{T}\le-\vec{s}.$
Then combining this with $\cdeg_{-\vec{s}}\mathbf{Q}_{1}=-\vec{s}_{2}$
we get $\cdeg_{-\vec{b}_{2}}\mathbf{N}_{2}^{T}\mathbf{Q}_{1}\le-\vec{s}_{2}$
using \prettyref{lem:predictableDegree}. Let $\hat{\mathbf{G}}=\mathbf{Q}_{1}\hat{\mathbf{Q}}_{2}$,
which is a $\left(\mathbf{N}^{T},-\vec{s}\right)$-kernel basis by
\prettyref{thm:continueComputingKernelBasisByRows}. Note that $\cdeg_{-\vec{s}_{2}}\hat{\mathbf{Q}}_{2}=\cdeg_{-\vec{s}}\mathbf{Q}_{1}\hat{\mathbf{Q}}_{2}=\cdeg_{-\vec{s}}\hat{\mathbf{G}}\le0.$
\end{proof}

\subsection{\label{sub:kernelBasisViaOrderBasisByRows}Efficient Computation
of Kernel Bases}

Now that we can correctly compute a $\left(\mathbf{N}^{T},-\vec{s}\right)$-kernel
basis by rows with the help of order basis computation using \prettyref{lem:kernelBasisOfSubsetOfRowsContainedInOrderBasis},
we need to look at how to do it efficiently. One major difficulty
is that the order $\vec{b}+1$, or equivalently, the $\vec{s}$-row
degrees of $\mathbf{N}_{1}^{T}$ are nonuniform and can have degree
as large as $\sum\vec{s}$. To overcome this, we separate the rows
of $\mathbf{N}^{T}$ into blocks according to their $\vec{s}$-row
degrees, and then work with these blocks one by one successively using
\prettyref{thm:continueComputingKernelBasisByRows}. 

\input{AlgorithmNullspaceBasisReverse.tex}

Let $k$ be the column dimension of $\mathbf{N}$ and $\xi$ be an
upper bound of $\sum\vec{s}$. Since 
\[
\sum\cdeg_{\vec{s}}\mathbf{N}=\sum\vec{b}\le\sum\vec{s}\le\xi
\]
 by \prettyref{thm:boundOfSumOfShiftedDegreesOfKernelBasis}, at most
$\frac{k}{c}$ columns of $\mathbf{N}$ have $\vec{s}$-column degrees
greater than or equal to $\frac{c~\xi}{k}$ for any $c\ge1$. Without
loss of generality we can assume that the rows of $\mathbf{N}^{T}$
are arranged in decreasing $\vec{s}$-row degrees. We divide $\mathbf{N}^{T}$
into $\log k$ row blocks according to the $\vec{s}$-row degrees
of its rows, or equivalently, divide $\mathbf{N}$ into blocks of
columns according to the $\vec{s}$-column degrees. Let 
\[
\mathbf{N}=\left[\mathbf{N}_{1},\mathbf{N}_{2},\cdots,\mathbf{N}_{\log k-1},\mathbf{N}_{\log k}\right]
\]
with $\mathbf{N}_{\log k},\mathbf{N}_{\log k-1},\dots,\mathbf{N}_{2},\mathbf{N}_{1}$
having $\vec{s}$-column degrees in the range $\left[0,2\xi/k\right]$,
$(2\xi/k,4\xi/k],$ $(4\xi/k,8\xi/k],\ ...,$ $(\xi/4,\xi/2],$ $(\xi/2,\xi].$
Let $\vec{\sigma}_{i}=\left[\xi/2^{i-1}+1,\dots,\xi/2^{i-1}+1\right]$
with the same dimension as the row dimension of $\mathbf{N}_{i}$
and 
\[
\vec{\sigma}=\left[\vec{\sigma}_{\log k},\vec{\sigma}_{\log k-1},\dots,\vec{\sigma}_{1}\right]
\]
 be the orders in the order basis computation.

To further simply our task, we also make the order of our problem
in each block uniform. Rather than of using $\mathbf{N}^{T}$ as the
input matrix, we instead use 
\begin{eqnarray*}
\hat{\mathbf{N}} & =\begin{bmatrix}\hat{\mathbf{N}}_{1}\\
\vdots\\
\hat{\mathbf{N}}_{\log k}
\end{bmatrix}= & x^{\vec{\sigma}-\vec{b}-1}\begin{bmatrix}\mathbf{N}_{1}^{T}\\
\vdots\\
\mathbf{N}_{\log k}^{T}
\end{bmatrix}=x^{\vec{\sigma}-\vec{b}-1}\mathbf{N}^{T}
\end{eqnarray*}
so that a $\left(\hat{\mathbf{N}},\vec{\sigma},-\vec{s}\right)$ order
basis is a $\left(\mathbf{N}^{T},\vec{b}+1,-\vec{s}\right)$ order
basis.

In order to compute a $\left(\mathbf{N}^{T},-\vec{s}\right)$-kernel
basis we determine a series of kernel bases via a series of order
basis computations as follows:
\begin{enumerate}
\item Let $\vec{s}_{1}=\vec{s}$. Compute an $\left(\hat{\mathbf{N}}_{1},\vec{\sigma}_{1},-\vec{s}_{1}\right)$
order basis $\mathbf{P}_{1}$ using Algorithm 2 from \cite{za2009}
for order basis computation with unbalanced shift. Partitioned $\mathbf{P}_{1}$
as $\mathbf{P}_{1}=\left[\mathbf{G}_{1},\mathbf{Q}_{1}\right]$, where
$\mathbf{G}_{1}$ is a $\left(\hat{\mathbf{N}}_{1},-\vec{s}_{1}\right)$-kernel
basis by \prettyref{lem:kernelBasisOfSubsetOfRowsContainedInOrderBasis}.
Set $\tilde{\mathbf{G}}_{1}=\mathbf{G}_{1}$ and $\vec{s}_{2}=-\cdeg_{-\vec{s}}\mathbf{G}_{1}$. 
\item Compute an $\left(\hat{\mathbf{N}}_{2}\tilde{\mathbf{G}}_{1},\vec{\sigma}_{2},-\vec{s}_{2}\right)$
order basis $\mathbf{P}_{2}$ and partition $\mathbf{P}_{2}=\left[\mathbf{G}_{2},\mathbf{Q}_{2}\right]$
with $\mathbf{G}_{2}$ a $\left(\hat{\mathbf{N}}_{2},-\vec{s}_{2}\right)$
kernel basis. Set $\vec{s}_{3}=-\cdeg_{-\vec{s}_{2}}\mathbf{G}_{2}$
and $\tilde{\mathbf{G}}_{2}=\tilde{\mathbf{G}}_{1}\mathbf{G}_{2}$.
\item Continuing this process, at each step $i$ we compute a $\left(\hat{\mathbf{N}}_{i}\tilde{\mathbf{G}}_{i-1},\vec{\sigma}_{i},-\vec{s}_{i}\right)$
order basis $\mathbf{P}_{i}$ and then partition $\mathbf{P}_{i}=\left[\mathbf{G}_{i},\mathbf{Q}_{i}\right]$
with $\mathbf{G}_{i}$ a $\left(\hat{\mathbf{N}}_{i}\tilde{\mathbf{G}}_{i-1},-\vec{s}_{i}\right)$
kernel basis. Let $\tilde{\mathbf{G}}_{i}=\prod_{j=1}^{i}\mathbf{G}_{i}=\tilde{\mathbf{G}}_{i-1}\mathbf{G}_{i}$. 
\item Return $\tilde{\mathbf{G}}_{\log k}$, a $\left(\mathbf{N}^{T},-\vec{s}\right)$-kernel
basis. 
\end{enumerate}
This process of computing a $\left(\mathbf{N}^{T},-\vec{s}\right)$-kernel
basis is formally given in Algorithm \ref{alg:minimalNullspaceBasisReverse}.


\subsection{Complexity of Left Kernel Computation}

The cost of Algorithm \ref{alg:minimalNullspaceBasisReverse} is dominated
by the order basis computations and the multiplications $\hat{\mathbf{N}}_{i}\tilde{\mathbf{G}}_{i-1}$
and $\tilde{\mathbf{G}}_{i-1}\mathbf{G}_{i}$. Let $s=\xi/n$.
\begin{lem}
An $\left(\hat{\mathbf{N}}_{i}\tilde{\mathbf{G}}_{i-1},\vec{\sigma}_{i},-\vec{s}_{i}\right)$
order basis can be computed with a cost of $O^{\sim}\left(n^{\omega}s\right)$. \end{lem}
\begin{proof}
Note that $\mathbf{N}_{i}$ has less than $2^{i}$ columns. Otherwise,
\[
\sum\cdeg_{\vec{s}}\mathbf{N}_{i}>2^{i}\xi/2^{i}=\xi,
\]
contradicting with 
\[
\sum\cdeg_{\vec{s}}\mathbf{N}=\sum\vec{b}\le\sum\vec{s}\le\xi.
\]
It follows that $\hat{\mathbf{N}}_{i}$, and therefore $\hat{\mathbf{N}}_{i}\tilde{\mathbf{G}}_{i-1}$,
also have less than $2^{i}$ rows. We also have $\vec{\sigma}_{i}=\left[\xi/2^{i-1}+1,\dots,\xi/2^{i-1}+1\right]$
with entries in $\Theta\left(\xi/2^{i}\right)$. Therefore, Algorithm
2 from \cite{za2009} for order basis computation with unbalanced
shift can be used with a cost of $O^{\sim}\left(n^{\omega}s\right)$. \end{proof}
\begin{lem}
The multiplications $\hat{\mathbf{N}}_{i}\tilde{\mathbf{G}}_{i-1}$
can be done with a cost of $O^{\sim}\left(n^{\omega}s\right)$.\end{lem}
\begin{proof}
The dimension of $\hat{\mathbf{N}}_{i}$ is bounded by $2^{i-1}\times n$
and $\sum\rdeg_{\vec{s}}\hat{\mathbf{N}}_{i}\le2^{i-1}\cdot\xi/2^{i-1}=\xi$.
We also have $\cdeg_{-\vec{s}}\tilde{\mathbf{G}}_{i-1}\le0$, or equivalently,
$\rdeg\tilde{\mathbf{G}}_{i-1}\le\vec{s}$. We can now use Theorem
\ref{thm:multiplyUnbalancedMatrices} to multiply $\tilde{\mathbf{G}}_{i-1}^{T}$
and $\hat{\mathbf{N}}_{i}^{T}$ with a cost of $O^{\sim}\left(n^{\omega}s\right)$.\end{proof}
\begin{lem}
The multiplication $\tilde{\mathbf{G}}_{i-1}\mathbf{G}_{i}$ can be
done with a cost of $O^{\sim}\left(n^{\omega}s\right)$. \end{lem}
\begin{proof}
We know $\cdeg_{-\vec{s}}\tilde{\mathbf{G}}_{i-1}=-\vec{s}_{i}$,
and $\cdeg_{-\vec{s}_{i}}\mathbf{G}_{i}=-\vec{s}_{i+1}\le0.$ In other
words, $\rdeg\mathbf{G}_{i}\le\vec{s}_{i}$, and $\rdeg_{\vec{s}_{i}}\tilde{\mathbf{G}}_{i-1}\le\vec{s}$,
hence we can again use Theorem \ref{thm:multiplyUnbalancedMatrices}
to multiply $\mathbf{G}_{i}^{T}$ and $\tilde{\mathbf{G}}_{i-1}^{T}$
with a cost of $O^{\sim}\left(n^{\omega}s\right)$. \end{proof}
\begin{lem}
\label{lem:costKernelBasisReverse}Given an input matrix $\mathbf{M}\in\mathbb{K}\left[x\right]^{k\times n}$,
a shift $\vec{s}\in\mathbb{Z}^{n}$, and an upper bound $\xi\in\mathbb{Z}$
such that 
\begin{itemize}
\item $\sum\rdeg_{\vec{s}}\mathbf{M}\le\xi$,
\item $\sum\vec{s}\le\xi$,
\item and any $\left(\mathbf{M},-\vec{s}\right)$-kernel basis having row
degrees bounded by $\vec{s}$, or equivalently, having $-\vec{s}$-column
degrees bounded by 0.
\end{itemize}
Then \prettyref{alg:minimalNullspaceBasisReverse} costs $O^{\sim}\left(n^{\omega}s\right)$
field operations to compute a $\left(\mathbf{M},-\vec{s}\right)$-kernel
basis.

Note that $\xi$ can be simply set to $\sum\vec{s}$.\end{lem}
\begin{thm}
A right factor $\mathbf{G}$ satisfying $\mathbf{F}=\mathbf{TG}$
for a column basis $\mathbf{T}$ can be computed with a cost of $O^{\sim}\left(n^{\omega}s\right)$. \end{thm}

