
\section{Column Basis via Factorization}

In this section we reduce the problem of determining a column basis
of a polynomial matrix into three separate processes. For this reduction
it turns out to be %Before discussing the efficient computation of column basis, it is 
useful to look at following relationship between column basis, kernel
basis, and unimodular matrices.
\begin{lem}
\label{lem:unimodular_kernel_columnBasis} Let $\mathbf{F}\in\mathbb{K}\left[x\right]^{m\times n}$
and suppose $\mathbf{U}\in\mathbb{K}\left[x\right]^{n\times n}$ is
a unimodular matrix such that $\mathbf{F}\mathbf{U}=\left[0,\mathbf{T}\right]$
with $\mathbf{T}$ of full column rank. Partition $\mathbf{U}=\left[\mathbf{U}_{L},\mathbf{U}_{R}\right]$
such that $\mathbf{F}\cdot\mathbf{U}_{L}=0$ and $\mathbf{F}\mathbf{U}_{R}=\mathbf{T}$.
Then 
\begin{enumerate}
\item $\mathbf{U}_{L}$ is a kernel basis of $\mathbf{F}$ and $\mathbf{T}$
is a column basis of $\mathbf{F}$. 
\item If $\mathbf{N}$ is any other kernel basis of $\mathbf{F}$, then
$\mathbf{U}^{*}=\left[\mathbf{N},~\mathbf{U}_{R}\right]$ is also
unimodular and also unimodularly transforms $\mathbf{F}$ to $\left[0,\mathbf{T}\right]$. 
\end{enumerate}
\end{lem}
\begin{proof}
Since $\mathbf{F}$ and $\left[0,\mathbf{T}\right]$ are unimodularly
equivalent with $\mathbf{F}$ having full column rank we have that
$\mathbf{T}$ is a column basis of $\mathbf{F}$. It remains to show
that $\mathbf{U}_{L}$ is a kernel basis of $\mathbf{F}$. Since $\mathbf{F}\mathbf{U}_{L}=0$,
$\mathbf{U}_{L}$ is generated by any kernel basis $\mathbf{N}$,
that is, $\mathbf{U}_{L}=\mathbf{N}\mathbf{C}$ for some polynomial
matrix $\mathbf{C}$. Let $r$ be the rank of $\mathbf{F}$, which
is also the column dimension of $\mathbf{T}$ and $\mathbf{U}_{R}$.
Then both $\mathbf{N}$ and $\mathbf{U}_{L}$ have column dimension
$n-r$. Hence $\mathbf{C}$ is a square $(n-r)\times(n-r)$ matrix.
The unimodular matrix $\mathbf{U}$ can be factored as 
\[
\mathbf{U}=\left[\mathbf{N}\mathbf{C},\mathbf{U}_{R}\right]=\left[\mathbf{N},\mathbf{U}_{R}\right]\begin{bmatrix}\mathbf{C} & 0\\
0 & I
\end{bmatrix},
\]
implying that both factors $\left[\mathbf{N},\mathbf{U}_{R}\right]$
and $\begin{bmatrix}\mathbf{C} & 0\\
0 & I
\end{bmatrix}$ are unimodular. Therefore, $\mathbf{C}$ is unimodular and $\mathbf{U}_{L}=\mathbf{N}\mathbf{C}$
is also a kernel basis. Notice that the unimodular matrix $\left[\mathbf{N},\mathbf{U}_{R}\right]$
also transforms $\mathbf{F}$ to $\left[0,\mathbf{T}\right]$. \end{proof}
\begin{rem}
\label{cor:unimodular_kernel_columnBasis2} It is interesting to see
what Lemma \ref{lem:unimodular_kernel_columnBasis} implies in the
case of unimodular matrices. Let $\mathbf{U}\in\mathbb{K}\left[x\right]^{n\times n}$
be a unimodular matrix with inverse $\mathbf{V}$, which, for a given
$k$, are partitioned as $\mathbf{U}=\left[\mathbf{U}_{L},\mathbf{U}_{R}\right]$
and $\mathbf{V}=\begin{bmatrix}\mathbf{V}_{U}\\
\mathbf{V}_{D}
\end{bmatrix}$ with $\mathbf{U}_{L}\in\mathbb{K}\left[x\right]^{n\times k}$ and
$\mathbf{V}_{U}\in\mathbb{K}\left[x\right]^{k\times n}$. Since $\mathbf{U}$
and $\mathbf{V}$ are inverses of each other we have the indentities
\begin{equation}
\mathbf{V}\mathbf{U}=\begin{bmatrix}\mathbf{V}_{U}\\
\mathbf{V}_{D}
\end{bmatrix}\begin{bmatrix}\mathbf{U}_{L},\mathbf{U}_{R}\end{bmatrix}=\begin{bmatrix}\mathbf{V}_{U}\mathbf{U}_{L} & \mathbf{V}_{U}\mathbf{U}_{R}\\
\mathbf{V}_{D}\mathbf{U}_{L} & \mathbf{V}_{D}\mathbf{U}_{R}
\end{bmatrix}=\begin{bmatrix}I & 0\\
0 & I
\end{bmatrix}.\label{inverse}
\end{equation}
Lemma \ref{lem:unimodular_kernel_columnBasis} then gives: 
\begin{enumerate}
\item $I_{r}$ is a column basis of $\mathbf{V}_{U}$ and a row basis of
$\mathbf{U}_{L}$, 
\item $I_{n-r}$ is a column basis of $\mathbf{V}_{D}$ and a row basis
of $\mathbf{U}_{R}$, 
\item $\mathbf{V}_{D}$ and $\mathbf{U}_{L}$ are kernel bases of each other, 
\item $\mathbf{V}_{U}$ and $\mathbf{U}_{R}$ are kernel bases of each other. 
\end{enumerate}
\end{rem}
\begin{lem}
\label{lem:matrixGCD} Let $\mathbf{F}\in\mathbb{K}\left[x\right]^{m\times n}$
with rank $r$. Suppose %\begin{itemize}
%\item[(i)]
 $\mathbf{N}\in\mathbb{K}\left[x\right]^{n\times(n-r)}$ is a right
kernel basis of $\mathbf{F}$ and % \item[(ii)]
$\mathbf{G}\in\mathbb{K}\left[x\right]^{r\times n}$ is a left kernel
basis of $\mathbf{N}$. %\end{itemize}
Then $\mathbf{F}=\mathbf{T}\cdot\mathbf{G}$ with $\mathbf{T}\in\mathbb{K}\left[x\right]^{m\times r}$
a column basis of $\mathbf{F}$. \end{lem}
\begin{proof}
Let $\mathbf{U}=\begin{bmatrix}\mathbf{U}_{L},\mathbf{U}_{R}\end{bmatrix}$
be a unimodular matrix with inverse $\mathbf{V}=\begin{bmatrix}\mathbf{V}_{U}\\
\mathbf{V}_{D}
\end{bmatrix}$ partitioned as in equation (\ref{inverse}) and satisfies $\mathbf{F}\cdot\mathbf{U}=\left[0,\mathbf{B}\right]$
with $\mathbf{B}\in\mathbb{K}\left[x\right]^{m\times r}$ a column
basis of $\mathbf{F}$. Then %\textbf{ 
\[
\mathbf{F}=\left[0,\mathbf{B}\right]\mathbf{U}^{-1}=\mathbf{B}\left[0,I\right]\mathbf{V}=\mathbf{B}\mathbf{V}_{D}.
\]
%}
Since $\mathbf{V}_{D}$ is a left kernel basis of\textbf{ $\mathbf{U}_{L}$},
any other left kernel basis $\mathbf{G}$ of $\mathbf{U}_{L}$ is
unimodularly equivalent to $\mathbf{V}_{D}$, that is, $\mathbf{V}_{D}=\mathbf{W}\cdot\mathbf{G}$
for some unimodular matrix $\mathbf{W}$. Thus $\mathbf{F}=\mathbf{B\cdot W}\cdot\mathbf{G}$.
Then $\mathbf{T}=\mathbf{B\cdot W}$ is a column basis of $\mathbf{F}$
since it is unimodularly equivalent to the column basis $\mathbf{B}$. 
\end{proof}
Lemma \ref{lem:matrixGCD} outlines a procedure for computing a column
basis of $\mathbf{F}$ with three main steps. The first step is to
compute a right kernel basis $\mathbf{N}$ of $\mathbf{F}$, something
which can be efficiently done using the fast kernel algorithm of \cite{za2012}.
The second step, computing a left kernel basis $\mathbf{G}$ for $\mathbf{N}$
 and the third step, computing the column basis $\mathbf{T}$ from
$\mathbf{F}$ and $\mathbf{G}$, will still require additional work
for efficient computation. Note that, while Lemma \ref{lem:matrixGCD}
does not require the bases computed to be minimal, working with minimal
kernel bases keeps the degrees well controlled, an important consideration
for efficient computation.
\begin{exmp}
Let 
\[
\mathbf{F}=\left[\begin{array}{cccc}
x^{2} & x^{2} & x+x^{2} & 1+x^{2}\\
1+x+x^{2} & x^{2} & 1+x^{2} & 1+x^{2}
\end{array}\right]~.
\]
Then the matrix 
\[
\mathbf{N}=\left[\begin{array}{cc}
x & 1\\
1 & x\\
x & 1\\
0 & x
\end{array}\right]
\]
is a right kernel basis of $\mathbf{F}$ and the matrix 
\[
\mathbf{G}=\left[\begin{array}{cccc}
1 & 0 & 1 & 0\\
\noalign{\medskip}x & {x}^{2} & 0 & 1+{x}^{2}
\end{array}\right]
\]
is a left nulllspace basis of $\mathbf{N}$. Finally the matrix 
\[
\mathbf{T}=\left[\begin{array}{cc}
x+x^{2} & 1\\
1+x^{2} & 1
\end{array}\right]
\]
satisfies $\mathbf{F}=\mathbf{T}\mathbf{G}$, and is a column basis
of $\mathbf{F}$. \end{exmp}

